{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2104f67-9cc3-4ff7-bf6b-2b6ac5921894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "from scipy.stats import norm\n",
    "\n",
    "from core import multi_evaluate, exp_aggregator, IdentityConv2d\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd50c712-4789-4ee2-9b33-737b17ff41df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "batch_size = 20\n",
    "num_neurons = 200\n",
    "data_path = 'data'\n",
    "\n",
    "transforms = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n",
    "])\n",
    "\n",
    "\n",
    "base_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='data', train=True, transform=transforms, download=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(base_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a45ec06-8862-434c-8dcf-863a1854292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot20(batch, name=\"\"):\n",
    "    # Create a 4x5 grid of subplots\n",
    "    fig, axs = plt.subplots(4, 5, figsize=(11.5, 9))\n",
    "    fig.subplots_adjust(hspace=0.1, wspace=0)\n",
    "    \n",
    "    # Inverse normalization parameters\n",
    "    mean = [0.4914, 0.4822, 0.4465]\n",
    "    std = [0.247, 0.243, 0.261]\n",
    "    \n",
    "    # Iterate over each subplot and plot the corresponding image\n",
    "    img_idx = 0\n",
    "    for i in range(4):\n",
    "        for j in range(5):\n",
    "            axs[i, j].axis('off')  # Turn off axis for each subplot in the grid\n",
    "            \n",
    "            # Undo normalization\n",
    "            img = batch[img_idx].permute(1, 2, 0).cpu().numpy()  # Convert from CHW to HWC format and to numpy array\n",
    "            img = (img * np.array(std)) + np.array(mean)  # Apply inverse normalization\n",
    "            img = np.clip(img, 0, 1)  # Clip values to be in the range [0, 1]\n",
    "            \n",
    "            axs[i, j].imshow(img)\n",
    "            img_idx += 1\n",
    "    \n",
    "    # Hide the main plot axes\n",
    "    plt.axis('off')\n",
    "    plt.suptitle(name)\n",
    "    \n",
    "    # Show the plot\n",
    "    #plt.savefig(name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b8a817-d2a6-4bbe-bd91-720f91b34598",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data, label = next(iter(val_loader))\n",
    "plot20(user_data, \"True user data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ccb680-86be-4ebf-b781-ece6edb48aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "layer = nn.Linear(3 * 32 * 32, num_neurons).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    layer.weight.data.normal_()\n",
    "    \n",
    "# QBI\n",
    "optimal_bias = norm.ppf(1 / batch_size) * np.sqrt(3 * 32 * 32)\n",
    "layer.bias.data.fill_(optimal_bias)\n",
    "\n",
    "model = IdentityConv2d(layer, 10)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16f9e2f-aeaa-496c-a8f3-799efceeba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(user_data)\n",
    "loss = criterion(output, label)\n",
    "loss.backward()\n",
    "\n",
    "w_grad = model.fc1.weight.grad.clone()\n",
    "b_grad = model.fc1.bias.grad.clone()\n",
    "\n",
    "intermediate = w_grad / b_grad.view(-1, 1)\n",
    "intermediate = intermediate.reshape(-1, 3, 32, 32).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8114c520-25aa-4514-9cb8-440f724c2dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [torch.zeros_like(user_data[0]) for _ in range(20)]\n",
    "\n",
    "for i, user_image in enumerate(user_data):\n",
    "    for n_grad in intermediate:\n",
    "        if torch.allclose(user_image, n_grad):\n",
    "            result[i] = n_grad\n",
    "            print(f\"Found image {i}\")\n",
    "            break\n",
    "plot20(result, \"Reconstructed data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
